{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"videos.txt\", 'r') as file:\n",
    "    videos = [line.strip() for line in file]\n",
    "\n",
    "transcripts = [YouTubeTranscriptApi.get_transcript(video_id) for video_id in videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import srt\n",
    "\n",
    "\n",
    "TRIGGER_LENGTH = 750  # 30-60 seconds\n",
    "\n",
    "def merge(subtitles, idx):\n",
    "    new_content = combine_content(subtitles)\n",
    "\n",
    "    # preserve start as timedelta\n",
    "    new_start = seconds_float_to_timedelta(subtitles[0][\"start\"])\n",
    "    # merge durations as timedelta\n",
    "    new_duration = seconds_float_to_timedelta(sum(sub[\"duration\"] for sub in subtitles))\n",
    "    \n",
    "    # combine\n",
    "    new_end = new_start + new_duration\n",
    "    \n",
    "    return srt.Subtitle(index=idx, start=new_start, end=new_end, content=new_content)\n",
    "\n",
    "\n",
    "def combine_content(subtitles):\n",
    "    contents = [subtitle[\"text\"].strip() for subtitle in subtitles]\n",
    "    return \" \".join(contents) + \"\\n\\n\"\n",
    "\n",
    "\n",
    "def get_charcount(subtitle):\n",
    "    return len(subtitle[\"text\"])\n",
    "\n",
    "\n",
    "def seconds_float_to_timedelta(x_seconds):\n",
    "    return timedelta(seconds=x_seconds)\n",
    "\n",
    "\n",
    "def merge_subtitles(subtitles):\n",
    "    merged_subtitles = []\n",
    "    current_chunk, current_length, chunk_idx = [], 0, 1\n",
    "\n",
    "    for subtitle in subtitles:\n",
    "        current_chunk.append(subtitle)\n",
    "        added_length = get_charcount(subtitle)\n",
    "        new_length = current_length + added_length\n",
    "\n",
    "        if new_length >= TRIGGER_LENGTH:\n",
    "            merged_subtitle = merge(current_chunk, chunk_idx)\n",
    "            merged_subtitles.append(merged_subtitle)\n",
    "            current_chunk, current_length = [], 0\n",
    "            chunk_idx += 1\n",
    "        else:\n",
    "            current_length = new_length\n",
    "\n",
    "    if current_chunk:\n",
    "        merged_subtitle = merge(current_chunk, chunk_idx)\n",
    "        merged_subtitles.append(merged_subtitle)\n",
    "\n",
    "    return merged_subtitles\n",
    "\n",
    "\n",
    "subtitle_collections = [merge_subtitles(transcript) for transcript in transcripts]\n",
    "\n",
    "# get strings as well for quick checks (and easier to write to files)\n",
    "subtitle_strings = [srt.compose(merged_subtitles) for merged_subtitles in subtitle_collections]\n",
    "\n",
    "base_url_format = \"https://www.youtube.com/watch?v={id}\"\n",
    "query_params_format = \"&t={start}s\"\n",
    "\n",
    "\n",
    "def create_split_video_df(subtitles, base_url):\n",
    "    rows = []\n",
    "    for subtitle in subtitles:\n",
    "        raw_text = subtitle.content\n",
    "        text = raw_text.strip()\n",
    "        start = timestamp_from_timedelta(subtitle.start)\n",
    "        url = base_url + query_params_format.format(start=start)\n",
    "\n",
    "        rows.append({\"text\": text, \"source\": url})\n",
    "\n",
    "    video_df = pd.DataFrame.from_records(rows)\n",
    "    return video_df\n",
    "\n",
    "\n",
    "def timestamp_from_timedelta(td):\n",
    "    return int(td.total_seconds())\n",
    "\n",
    "\n",
    "split_video_dfs = [\n",
    "    create_split_video_df(subtitles, base_url_format.format(id=video_id))\n",
    "    for subtitles, video_id in zip(subtitle_collections, videos)\n",
    "]\n",
    "\n",
    "split_video_df = pd.concat(split_video_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_json = split_video_df.to_json(orient=\"index\")\n",
    "\n",
    "with open(\"documents.json\", \"w\") as f:\n",
    "    f.write(documents_json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings and load to vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"documents.json\") as f:\n",
    "    s = f.read()\n",
    "    \n",
    "json_data = json.loads(s).values()\n",
    "\n",
    "sentences = []\n",
    "for d in json_data:\n",
    "    sentences.append(d[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/Devel/W008/env2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = model.encode(sentences[:3], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "collection = \"MIT6.824\"\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import PointStruct\n",
    "import uuid\n",
    "\n",
    "def to_point(vector, payload):\n",
    "    return PointStruct(id = str(uuid.uuid4()), vector = vector, payload = payload)\n",
    "\n",
    "def create_points(vectors, data):\n",
    "    points = []\n",
    "    for i, item in enumerate(data):\n",
    "        points.append(to_point(vectors[i], item))\n",
    "    return points\n",
    "\n",
    "points = create_points(embs, list(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "operation_info = client.upsert(\n",
    "    collection_name=collection,\n",
    "    wait=True,\n",
    "    points=points,\n",
    ")\n",
    "\n",
    "operation_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.youtube.com/watch?v=cQP8WApzIQQ&t=3003s', 'text': \"and the idea is that the programmer just write the application designer consumer of this distributed computation I'm just be able to write a simple map function and a simple reduce function that don't know anything about distribution and the MapReduce framework would take care of everything else so an abstract view of how what MapReduce is up to is it starts by assuming that there's some input and the input is split up into some a whole bunch of different files or chunks in some way so we're imagining that no yeah you know input file one and put file two etc you know these inputs are maybe you know web pages crawled from the web or more likely sort of big files that contain many web each of which contains many web files crawl from the web all right and the way Map Reduce\"}\n",
      "{'source': 'https://www.youtube.com/watch?v=cQP8WApzIQQ&t=3064s', 'text': \"starts is that you're to find a map function and the MapReduce framework is gonna run your map function on each of the input files and of course you can see here there's some obvious parallelism available can run the maps in parallel so the each of these map functions only looks as this input and produces output the output that a map function is required to produce is a list you know it takes a file as input and the file is some fraction of the input data and it produces a list of key value pairs as output the map function and so for example let's suppose we're writing the simplest possible MapReduce example a word count MapReduce job goal is to count the number of occurrences of each word so your map function might emit key value pairs where the key is the word and the value is just one so\"}\n",
      "{'source': 'https://www.youtube.com/watch?v=cQP8WApzIQQ&t=4751s', 'text': \"was extremely fast okay we're out of time for MapReduce we have a lab due at the end of next week in which you'll write your own somewhat simplified MapReduce so have fun with that and see you on Thursday\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"mapreduce model\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "search_result = client.search(\n",
    "    collection_name=collection, query_vector=query_embedding, limit=3\n",
    ")\n",
    "\n",
    "for r in search_result:\n",
    "    print(r.payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: mapreduce model\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "{'text': \"and the idea is that the programmer just write the application designer consumer of this distributed computation I'm just be able to write a simple map function and a simple reduce function that don't know anything about distribution and the MapReduce framework would take care of everything else so an abstract view of how what MapReduce is up to is it starts by assuming that there's some input and the input is split up into some a whole bunch of different files or chunks in some way so we're imagining that no yeah you know input file one and put file two etc you know these inputs are maybe you know web pages crawled from the web or more likely sort of big files that contain many web each of which contains many web files crawl from the web all right and the way Map Reduce\", 'source': 'https://www.youtube.com/watch?v=cQP8WApzIQQ&t=3003s'} (Score: 0.6638)\n",
      "{'text': \"starts is that you're to find a map function and the MapReduce framework is gonna run your map function on each of the input files and of course you can see here there's some obvious parallelism available can run the maps in parallel so the each of these map functions only looks as this input and produces output the output that a map function is required to produce is a list you know it takes a file as input and the file is some fraction of the input data and it produces a list of key value pairs as output the map function and so for example let's suppose we're writing the simplest possible MapReduce example a word count MapReduce job goal is to count the number of occurrences of each word so your map function might emit key value pairs where the key is the word and the value is just one so\", 'source': 'https://www.youtube.com/watch?v=cQP8WApzIQQ&t=3064s'} (Score: 0.6468)\n",
      "{'text': \"was extremely fast okay we're out of time for MapReduce we have a lab due at the end of next week in which you'll write your own somewhat simplified MapReduce so have fun with that and see you on Thursday\", 'source': 'https://www.youtube.com/watch?v=cQP8WApzIQQ&t=4751s'} (Score: 0.6348)\n"
     ]
    }
   ],
   "source": [
    "# query = \"mapreduce model\"\n",
    "# query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# cos_scores = util.cos_sim(query_embedding, embs).squeeze()\n",
    "# top_results = torch.topk(cos_scores, k=3)\n",
    "# print(\"Query:\", query)\n",
    "# print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "# for score, idx in zip(top_results[0], top_results[1]):\n",
    "#     print(list(json_data)[idx], \"(Score: {:.4f})\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
